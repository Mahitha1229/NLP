{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a5a0db1",
   "metadata": {},
   "source": [
    "# Trie-Based Stemming Analysis\n",
    "\n",
    "This notebook explores stemming using prefix and suffix tries. We analyze a list of nouns from `brown_nouns.txt` and identify stem + suffix pairs based on branching heuristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b334e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries and Trie classes\n",
    "from collections import defaultdict\n",
    "\n",
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.children = defaultdict(TrieNode)\n",
    "        self.count = 0\n",
    "\n",
    "class Trie:\n",
    "    def __init__(self, reverse=False):\n",
    "        self.root = TrieNode()\n",
    "        self.reverse = reverse\n",
    "\n",
    "    def insert(self, word):\n",
    "        if self.reverse:\n",
    "            word = word[::-1]\n",
    "        node = self.root\n",
    "        for char in word:\n",
    "            node = node.children[char]\n",
    "            node.count += 1\n",
    "\n",
    "    def find_split(self, word):\n",
    "        if self.reverse:\n",
    "            word = word[::-1]\n",
    "        node = self.root\n",
    "        max_branch = 0\n",
    "        split_index = 0\n",
    "        for i, char in enumerate(word):\n",
    "            node = node.children[char]\n",
    "            branch_count = len(node.children)\n",
    "            if branch_count > max_branch:\n",
    "                max_branch = branch_count\n",
    "                split_index = i + 1\n",
    "        if self.reverse:\n",
    "            stem = word[:split_index][::-1]\n",
    "            suffix = word[split_index:][::-1]\n",
    "        else:\n",
    "            stem = word[:split_index]\n",
    "            suffix = word[split_index:]\n",
    "        return stem, suffix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023ae10b",
   "metadata": {},
   "source": [
    "## Loading Words and Analyzing Tries\n",
    "\n",
    "We load the nouns from the text file and analyze them using both prefix and suffix tries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18145a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and analyzing\n",
    "def load_words(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        words = [line.strip().lower() for line in f if line.strip()]\n",
    "    return words\n",
    "\n",
    "def analyze_trie(words, reverse=False):\n",
    "    trie = Trie(reverse=reverse)\n",
    "    for word in words:\n",
    "        trie.insert(word)\n",
    "    results = {}\n",
    "    for word in words:\n",
    "        stem, suffix = trie.find_split(word)\n",
    "        results[word] = (stem, suffix)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f06ee4e",
   "metadata": {},
   "source": [
    "## Comparing Prefix vs Suffix Tries\n",
    "\n",
    "We compare the total suffix lengths to determine which trie gives better stem separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a71d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison and Output\n",
    "def compare_tries(filepath, output_file):\n",
    "    words = load_words(filepath)\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as out:\n",
    "        out.write(\"Prefix Trie Stemming:\\n\")\n",
    "        prefix_results = analyze_trie(words, reverse=False)\n",
    "        for word, (stem, suffix) in prefix_results.items():\n",
    "            out.write(f\"{word} = {stem}+{suffix}\\n\")\n",
    "\n",
    "        out.write(\"\\nSuffix Trie Stemming:\\n\")\n",
    "        suffix_results = analyze_trie(words, reverse=True)\n",
    "        for word, (stem, suffix) in suffix_results.items():\n",
    "            out.write(f\"{word} = {stem}+{suffix}\\n\")\n",
    "\n",
    "        prefix_suffix_total = sum(len(suffix) for _, suffix in prefix_results.values())\n",
    "        suffix_suffix_total = sum(len(suffix) for _, suffix in suffix_results.values())\n",
    "\n",
    "        out.write(\"\\nComparison:\\n\")\n",
    "        out.write(f\"Total suffix length in Prefix Trie: {prefix_suffix_total}\\n\")\n",
    "        out.write(f\"Total suffix length in Suffix Trie: {suffix_suffix_total}\\n\")\n",
    "        better = \"Prefix Trie\" if prefix_suffix_total < suffix_suffix_total else \"Suffix Trie\"\n",
    "        out.write(f\"Better stemming achieved by: {better}\\n\")\n",
    "\n",
    "compare_tries(\"brown_nouns.txt\", \"stemming_output.txt\")\n",
    "\n",
    "# Reading and printing the output\n",
    "with open(\"stemming_output.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    print(f.read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
